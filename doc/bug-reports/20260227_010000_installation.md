# Bug Report — 설치(Installation) 및 운영(Operations) 과정 버그 7건

- **작성일시(Timestamp)**: 2026-02-27 01:00 KST(Korean Standard Time)
- **환경(Environment)**: M4 Max MacBook Pro (16 CPU, 128GB RAM), macOS Darwin 24.6.0
- **인프라(Infrastructure)**: Tart VM(Virtual Machine) 10개, K8s(Kubernetes) 4 클러스터(Cluster) — kubeadm v1.31

---

## BUG-001: ssh_exec_sudo 따옴표(Quote) 깨짐

| 항목(Field) | 내용(Detail) |
|------|------|
| 타임스탬프(Timestamp) | 2026-02-27 01:00 |
| 심각도(Severity) | High |
| 카테고리(Category) | SSH(Secure Shell) |
| 발견 단계(Phase) | Phase 2 — 노드 준비(Node Preparation) |

### 증상(Symptom)
```
sed: -e expression #1, char 15: unterminated `s' command
```

### 원인(Root Cause)
`ssh_exec_sudo` 함수가 `bash -c '$*'` 형태로 명령을 전달하여, `sed`, `iptables` 등 작은따옴표가 포함된 명령의 이스케이핑(Escaping)이 깨짐.

### 해결(Fix)
```bash
# Before (broken)
ssh_exec "$ip" "echo '$password' | sudo -S bash -c '$*'"

# After (fixed) — heredoc 방식
sshpass -p "$password" ssh $SSH_OPTS "${user}@${ip}" sudo bash -s <<EOF
$*
EOF
```

### 수정 파일(Modified Files)
- `scripts/lib/ssh.sh` — ssh_exec_sudo 함수

### 교훈(Lesson)
원격 서버에 복잡한 명령을 전달할 때 heredoc이 안전. `bash -c` 중첩은 특수문자 이스케이핑(Escaping) 지옥을 유발.

---

## BUG-002: conntrack 패키지(Package) 미설치

| 항목(Field) | 내용(Detail) |
|------|------|
| 타임스탬프(Timestamp) | 2026-02-27 01:15 |
| 심각도(Severity) | High |
| 카테고리(Category) | K8s(Kubernetes) |
| 발견 단계(Phase) | Phase 5 — 클러스터 초기화(Cluster Initialization) |

### 증상(Symptom)
```
[ERROR FileExisting-conntrack]: conntrack not found in system path
```

### 원인(Root Cause)
kubeadm init 프리플라이트(Preflight) 체크에서 `conntrack`이 필수인데 Tart Ubuntu 기본 이미지(Base Image)에 미포함.

### 해결(Fix)
```bash
apt-get install -y -qq containerd apt-transport-https ca-certificates curl gnupg conntrack
```

### 수정 파일(Modified Files)
- `scripts/lib/k8s.sh` — install_containerd 함수

---

## BUG-003: VM 간 통신(Communication) 불가 — Shared Network

| 항목(Field) | 내용(Detail) |
|------|------|
| 타임스탬프(Timestamp) | 2026-02-27 01:30 |
| 심각도(Severity) | **Critical** |
| 카테고리(Category) | 네트워크(Network) |
| 발견 단계(Phase) | Phase 5 — 클러스터 초기화(Cluster Initialization) |

### 증상(Symptom)
```
$ ping -c 2 192.168.66.2  # worker1 → master
From 192.168.66.3 icmp_seq=1 Destination Host Unreachable
100% packet loss
```
kubeadm join 실패 — API(Application Programming Interface) 서버 접근 불가:
```
error execution phase preflight: couldn't validate the identity of the API Server
```

### 원인(Root Cause)
Tart 기본 shared networking(NAT, Network Address Translation)에서 VM→VM 직접 통신이 차단됨. macOS Virtualization.framework의 NAT 모드는 호스트(Host)→VM만 허용.

### 트러블슈팅 과정(Troubleshooting Process)
1. `ping` VM→VM 실패 확인
2. `--net-bridged=en0` 시도 → IP(Internet Protocol) 할당 자체 실패
3. Tart 문서에서 `--net-softnet-allow` 플래그(Flag) 발견
4. `--net-softnet-allow=0.0.0.0/0` 적용 → 소프트웨어 네트워킹(Software Networking)으로 VM 간 통신 허용

### 해결(Fix)
```bash
# Before
tart run "$vm_name" --no-graphics &

# After
tart run "$vm_name" --no-graphics --net-softnet-allow=0.0.0.0/0 &
```
IP 대역 변경: `192.168.66.x` → `192.168.65.x`

### 수정 파일(Modified Files)
- `scripts/lib/vm.sh` — vm_start 함수

### 교훈(Lesson)
Tart shared networking은 기본적으로 L2(Layer 2) 격리(Isolation)가 적용됨. 멀티 VM 클러스터 환경에서는 `--net-softnet-allow` 필수.

---

## BUG-004: Cilium K8s API 서버 접근 실패 — 부트스트랩 순환의존성(Circular Dependency)

| 항목(Field) | 내용(Detail) |
|------|------|
| 타임스탬프(Timestamp) | 2026-02-27 02:00 |
| 심각도(Severity) | **Critical** |
| 카테고리(Category) | CNI(Container Network Interface) |
| 발견 단계(Phase) | Phase 6 — Cilium 설치 |

### 증상(Symptom)
```
level=error msg="Unable to contact k8s api-server"
ipAddr=https://10.96.0.1:443
error="dial tcp 10.96.0.1:443: i/o timeout"
```

### 원인(Root Cause)
`kubeadm init --skip-phases=addon/kube-proxy`로 kube-proxy를 건너뛰었으므로, ClusterIP(10.96.0.1)로의 라우팅(Routing)이 존재하지 않음. Cilium이 이를 대체해야 하지만 부트스트랩(Bootstrap) 시점에는 아직 Cilium 자체가 동작 전인 치킨-에그(Chicken-and-Egg) 문제.

### 해결(Fix)
```bash
helm upgrade --install cilium cilium/cilium \
  --set k8sServiceHost="$master_ip" \
  --set k8sServicePort=6443 \
  ...
```
마스터 노드의 실제 IP를 직접 지정하여 ClusterIP 우회(Bypass).

### 수정 파일(Modified Files)
- `scripts/lib/k8s.sh` — install_cilium 함수

### 교훈(Lesson)
kube-proxy 대체(Replacement) 모드에서 Cilium 설치 시, 부트스트랩 단계에는 ClusterIP 라우팅이 없으므로 반드시 `k8sServiceHost`로 마스터 실제 IP를 지정해야 함.

---

## BUG-005: wait_nodes_ready `wc` 파싱(Parsing) 에러

| 항목(Field) | 내용(Detail) |
|------|------|
| 타임스탬프(Timestamp) | 2026-02-27 02:30 |
| 심각도(Severity) | Medium |
| 카테고리(Category) | 스크립트(Script) |
| 발견 단계(Phase) | Phase 6 — Cilium 설치 후 노드 대기 |

### 증상(Symptom)
```
[[: 0
99: syntax error in expression (error token is "99")
```

### 원인(Root Cause)
macOS의 `wc -l` 출력에 선행 공백(Leading Spaces)이 포함되어 비교 실패. Linux와 macOS 간 `wc` 출력 형식(Output Format) 차이.

### 해결(Fix)
```bash
# Before
not_ready=$(kubectl_cmd ... | grep -v "Ready" | wc -l || echo "99")

# After
not_ready=$(kubectl_cmd ... | grep -cv " Ready " || true)
```

### 수정 파일(Modified Files)
- `scripts/lib/k8s.sh` — wait_nodes_ready 함수

---

## BUG-006: Jenkins PVC(PersistentVolumeClaim) Pending + Helm Values 키(Key) 변경

| 항목(Field) | 내용(Detail) |
|------|------|
| 타임스탬프(Timestamp) | 2026-02-27 03:00 |
| 심각도(Severity) | High |
| 카테고리(Category) | CI/CD(Continuous Integration / Continuous Delivery) |
| 발견 단계(Phase) | Phase 8 — CI/CD 설치 |

### 증상(Symptom)
```
Warning  FailedScheduling  pod has unbound immediate PersistentVolumeClaims
```
```
Error: `controller.adminPassword` no longer exists. It has been renamed to `controller.admin.password`
```

### 원인(Root Cause)
1. kubeadm 기본 설치에는 SC(StorageClass)가 없어 PVC(PersistentVolumeClaim) 바인딩(Binding) 불가
2. Jenkins Helm 차트(Chart) 최신 버전에서 `controller.adminPassword` → `controller.admin.password`로 키 변경(Breaking Change)

### 해결(Fix)
```bash
# 1. StorageClass 추가(Add StorageClass)
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.28/deploy/local-path-storage.yaml
kubectl patch storageclass local-path -p '{"metadata":{"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```
```yaml
# 2. Values 키 수정(Fix Values Key)
controller:
  admin:
    password: admin
```

### 수정 파일(Modified Files)
- `scripts/install/08-install-cicd.sh` — local-path-provisioner 설치 추가
- `manifests/jenkins-values.yaml` — admin.password 키 변경

---

## BUG-007: prod-master kubeadm init CPU 부족(Insufficient CPU) 오류

| 항목(Field) | 내용(Detail) |
|------|------|
| 타임스탬프(Timestamp) | 2026-02-27 14:40 |
| 심각도(Severity) | High |
| 카테고리(Category) | 설정(Configuration) |
| 발견 단계(Phase) | Phase 5 — prod 클러스터 초기화 |

### 증상(Symptom)
```
[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2
```

### 원인(Root Cause)
prod-master VM에 CPU를 1개만 할당했으나, kubeadm init의 프리플라이트(Preflight) 체크에서 최소 2 CPU를 요구.

### 해결(Fix)
```json
// Before
{ "name": "prod-master", "role": "master", "cpu": 1, "memory": 3072, "disk": 20 }

// After
{ "name": "prod-master", "role": "master", "cpu": 2, "memory": 3072, "disk": 20 }
```

### 수정 파일(Modified Files)
- `config/clusters.json` — prod-master cpu: 1 → 2
- `terraform/variables.tf` — prod-master cpu: 1 → 2

### 교훈(Lesson)
kubeadm 컨트롤 플레인(Control Plane)은 최소 2 CPU 필수. IaC(Infrastructure as Code) 설정 변경 시 Bash 스크립트와 Terraform 양쪽 모두 동기화(Sync) 필요.

---

## 버그 통계(Bug Statistics)

| 카테고리(Category) | 건수(Count) | 심각도 분포(Severity Distribution) |
|----------|------|------------|
| Network / CNI(Container Network Interface) | 2 | Critical: 2 |
| K8s(Kubernetes) / CI/CD | 2 | High: 2 |
| SSH(Secure Shell) | 1 | High: 1 |
| 설정(Configuration) | 1 | High: 1 |
| 스크립트(Script) | 1 | Medium: 1 |
| **합계(Total)** | **7** | Critical: 2, High: 4, Medium: 1 |
